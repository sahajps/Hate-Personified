{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633456f2-7524-4870-95c0-a5406aa3cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5b037a-2646-47e0-9bd0-b6cf2091a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For arabic\n",
    "files = ['PA_base']\n",
    "\n",
    "def map_fn(row):\n",
    "    row = str(row)\n",
    "    if(re.search('نعم', row) and re.search('لا', row)):\n",
    "        return None\n",
    "    elif(re.search('نعم', row)):\n",
    "        return 1\n",
    "    elif(re.search('لا', row)):\n",
    "        return 0\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b47829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For hindi\n",
    "files = ['PH_base']\n",
    "\n",
    "def map_fn(row):\n",
    "    row = str(row)\n",
    "    if(re.search('हाँ', row) or re.search('हां', row) or re.search('जी', row)):\n",
    "        return 1\n",
    "    elif(re.search('नहीं', row) or re.search('गलत', row)):\n",
    "        return 0\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20022a3a-6c64-4838-9a99-6c802c1e14a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(files):\n",
    "    df = pd.read_excel('../OS_LLMs/'+f+'.xlsx')\n",
    "    col = df.columns[3:]\n",
    "    \n",
    "    no_ans = []\n",
    "    F1 = []\n",
    "    IAA = []\n",
    "    HS = []\n",
    "    \n",
    "    for i in col:\n",
    "        df[i] = df[i].apply(lambda x: str(x).lower())\n",
    "        df[i] = df[i].apply(map_fn)\n",
    "\n",
    "        pen = (df.shape[0]-df[i].isna().sum())/df.shape[0]\n",
    "        no_ans.append(df[i].isna().sum())\n",
    "\n",
    "        tmp = df[['label', i]].dropna()\n",
    "\n",
    "        F1.append(pen*f1_score(tmp['label'], tmp[i], average='weighted'))\n",
    "        IAA.append(pen*cohen_kappa_score(tmp['label'], tmp[i]))\n",
    "        HS.append(tmp[tmp[i]==1].shape[0]/tmp.shape[0])\n",
    "    \n",
    "    res = pd.read_csv('Performance_LocalLLMs.csv')\n",
    "    res[f+' Hal'] = no_ans\n",
    "    res[f+' F1'] = F1\n",
    "    res[f+' IAA'] = IAA\n",
    "    #res[f+' HS'] = HS\n",
    "    res.to_csv('Performance_LocalLLMs.csv', index=False)\n",
    "    \n",
    "#no_ans[-1], F1[-1], IAA[-1], HS[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591b4c7b-bed8-4849-aa63-165a76fd5483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt\n",
      "نعم، ال       121\n",
      "لا، البي      119\n",
      "أعتذر          96\n",
      "آسف،           42\n",
      "أنا آ          25\n",
      "البيان الم     17\n",
      "أعتقد          10\n",
      "لا، لا ي        8\n",
      "نعم، ي          8\n",
      "عذرً            7\n",
      "نعم، الت        5\n",
      "شكرً            5\n",
      "أنا مس          3\n",
      "أنا مج          3\n",
      "لا يجوز         3\n",
      "أنا أع          2\n",
      "التحرش          2\n",
      "لا يوجد         2\n",
      "لا يمكن         2\n",
      "صباح ال         1\n",
      "يجب تج          1\n",
      "لا يكره         1\n",
      "رعي الغ         1\n",
      "نعم، أ          1\n",
      "لا أستطي        1\n",
      "أنا بر          1\n",
      "بالعكس          1\n",
      "نعم, ال         1\n",
      "بارك الل        1\n",
      "المال ز         1\n",
      "الدين الإ       1\n",
      "البيان ال       1\n",
      "لا، ليس         1\n",
      "أنا لا          1\n",
      "لا، شمام        1\n",
      "اللاجئ          1\n",
      "لا يجب است      1\n",
      "في بلاد         1\n",
      "أنا أف          1\n",
      "Name: count, dtype: int64\n",
      "Index(['نعم، ال', 'لا، البي', 'أعتذر', 'آسف،', 'أنا آ', 'البيان الم', 'أعتقد',\n",
      "       'لا، لا ي', 'نعم، ي', 'عذرً', 'نعم، الت', 'شكرً', 'أنا مس', 'أنا مج',\n",
      "       'لا يجوز', 'أنا أع', 'التحرش', 'لا يوجد', 'لا يمكن', 'صباح ال',\n",
      "       'يجب تج', 'لا يكره', 'رعي الغ', 'نعم، أ', 'لا أستطي', 'أنا بر',\n",
      "       'بالعكس', 'نعم, ال', 'بارك الل', 'المال ز', 'الدين الإ', 'البيان ال',\n",
      "       'لا، ليس', 'أنا لا', 'لا، شمام', 'اللاجئ', 'لا يجب است', 'في بلاد',\n",
      "       'أنا أف'],\n",
      "      dtype='object', name='gpt')\n"
     ]
    }
   ],
   "source": [
    "# Sample code check mapping from words to labels\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_excel('../OS_LLMs/'+f+'.xlsx')\n",
    "\n",
    "    print(df.gpt.value_counts())\n",
    "    print(df.gpt.value_counts().index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
